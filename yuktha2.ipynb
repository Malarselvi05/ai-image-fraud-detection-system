{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5b2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8524df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Device\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------------------\n",
    "# Paths\n",
    "# ----------------------------\n",
    "dataset_path = r\"D:\\Users\\Lenova\\Desktop\\YukTha\\dataset\"\n",
    "train_dir = os.path.join(dataset_path, \"train\")\n",
    "val_dir = os.path.join(dataset_path, \"val\")\n",
    "\n",
    "# ----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e590eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'ai': 0, 'real': 1}\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation (Prevents Overfitting)\n",
    "# ----------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "\n",
    "    # ğŸ”¥ New Robust Augmentations\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.3,\n",
    "        contrast=0.3,\n",
    "        saturation=0.3,\n",
    "        hue=0.1\n",
    "    ),\n",
    "\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"Class mapping:\", train_dataset.class_to_idx)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… v2 model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v2(weights=None)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(model.last_channel, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 2)\n",
    ")\n",
    "\n",
    "MODEL_PATH = r\"D:\\Users\\Lenova\\Desktop\\YukTha\\models\\mobilenet_food_model_v2.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"âœ… v2 model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a0b06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c244636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: D:\\Users\\Lenova\\Desktop\\YukTha\\models\\mobilenet_food_model_v3.pth\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = r\"D:\\Users\\Lenova\\Desktop\\YukTha\\models\\mobilenet_food_model_v3.pth\"\n",
    "\n",
    "print(\"Loading model from:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ead7e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# 1. Load model\n",
    "\n",
    "#v4\n",
    "model = models.mobilenet_v2(weights=None)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(model.last_channel, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 2)\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "933d0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze early layers (keep high-level features stable)\n",
    "for param in model.features[:10].parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47196c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "033bc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/3]\n",
      "Train Loss: 32.0159\n",
      "Train Acc: 0.9330\n",
      "Val Acc: 0.9583\n",
      "\n",
      "Epoch [2/3]\n",
      "Train Loss: 35.0952\n",
      "Train Acc: 0.9283\n",
      "Val Acc: 0.9467\n",
      "\n",
      "Epoch [3/3]\n",
      "Train Loss: 32.8183\n",
      "Train Acc: 0.9313\n",
      "Val Acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {running_loss:.4f}\")\n",
    "    print(f\"Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb70cbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ v4 model saved successfully\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = r\"D:\\Users\\Lenova\\Desktop\\YukTha\\models\\mobilenet_food_model_v4.pth\"\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print(\"ğŸ”¥ v4 model saved successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "203c1e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 0, 'real': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fdb5348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.26.0-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from lime) (3.10.8)\n",
      "Requirement already satisfied: numpy in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from lime) (2.3.5)\n",
      "Requirement already satisfied: scipy in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from lime) (1.16.3)\n",
      "Requirement already satisfied: tqdm in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from lime) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from lime) (1.8.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from scikit-image) (3.6.1)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from scikit-image) (12.1.1)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2026.2.16-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from scikit-image) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from scikit-learn>=0.18->lime) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from matplotlib->lime) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from matplotlib->lime) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from matplotlib->lime) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from matplotlib->lime) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from matplotlib->lime) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages (from tqdm->lime) (0.4.6)\n",
      "Downloading scikit_image-0.26.0-cp313-cp313-win_amd64.whl (11.9 MB)\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.9 MB 285.6 kB/s eta 0:00:40\n",
      "   - -------------------------------------- 0.5/11.9 MB 285.6 kB/s eta 0:00:40\n",
      "   - -------------------------------------- 0.5/11.9 MB 285.6 kB/s eta 0:00:40\n",
      "   - -------------------------------------- 0.5/11.9 MB 285.6 kB/s eta 0:00:40\n",
      "   -- ------------------------------------- 0.8/11.9 MB 329.1 kB/s eta 0:00:34\n",
      "   -- ------------------------------------- 0.8/11.9 MB 329.1 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.0/11.9 MB 357.9 kB/s eta 0:00:31\n",
      "   --- ------------------------------------ 1.0/11.9 MB 357.9 kB/s eta 0:00:31\n",
      "   --- ------------------------------------ 1.0/11.9 MB 357.9 kB/s eta 0:00:31\n",
      "   --- ------------------------------------ 1.0/11.9 MB 357.9 kB/s eta 0:00:31\n",
      "   --- ------------------------------------ 1.0/11.9 MB 357.9 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 333.7 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 333.7 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 333.7 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 333.7 kB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 321.7 kB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 321.7 kB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 321.7 kB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 321.7 kB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 321.7 kB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 321.7 kB/s eta 0:00:33\n",
      "   ------ --------------------------------- 1.8/11.9 MB 297.1 kB/s eta 0:00:34\n",
      "   ------ --------------------------------- 1.8/11.9 MB 297.1 kB/s eta 0:00:34\n",
      "   ------ --------------------------------- 1.8/11.9 MB 297.1 kB/s eta 0:00:34\n",
      "   ------ --------------------------------- 1.8/11.9 MB 297.1 kB/s eta 0:00:34\n",
      "   ------ --------------------------------- 1.8/11.9 MB 297.1 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.1/11.9 MB 291.4 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.1/11.9 MB 291.4 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.1/11.9 MB 291.4 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.1/11.9 MB 291.4 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.1/11.9 MB 291.4 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.4/11.9 MB 285.9 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.4/11.9 MB 285.9 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.4/11.9 MB 285.9 kB/s eta 0:00:34\n",
      "   ------- -------------------------------- 2.4/11.9 MB 285.9 kB/s eta 0:00:34\n",
      "   -------- ------------------------------- 2.6/11.9 MB 287.9 kB/s eta 0:00:33\n",
      "   -------- ------------------------------- 2.6/11.9 MB 287.9 kB/s eta 0:00:33\n",
      "   -------- ------------------------------- 2.6/11.9 MB 287.9 kB/s eta 0:00:33\n",
      "   -------- ------------------------------- 2.6/11.9 MB 287.9 kB/s eta 0:00:33\n",
      "   -------- ------------------------------- 2.6/11.9 MB 287.9 kB/s eta 0:00:33\n",
      "   --------- ------------------------------ 2.9/11.9 MB 282.9 kB/s eta 0:00:32\n",
      "   --------- ------------------------------ 2.9/11.9 MB 282.9 kB/s eta 0:00:32\n",
      "   --------- ------------------------------ 2.9/11.9 MB 282.9 kB/s eta 0:00:32\n",
      "   --------- ------------------------------ 2.9/11.9 MB 282.9 kB/s eta 0:00:32\n",
      "   --------- ------------------------------ 2.9/11.9 MB 282.9 kB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 3.1/11.9 MB 280.4 kB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 3.1/11.9 MB 280.4 kB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 3.1/11.9 MB 280.4 kB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 3.1/11.9 MB 280.4 kB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 3.1/11.9 MB 280.4 kB/s eta 0:00:32\n",
      "   ----------- ---------------------------- 3.4/11.9 MB 277.5 kB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 3.4/11.9 MB 277.5 kB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 3.4/11.9 MB 277.5 kB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 3.4/11.9 MB 277.5 kB/s eta 0:00:31\n",
      "   ------------ --------------------------- 3.7/11.9 MB 279.5 kB/s eta 0:00:30\n",
      "   ------------ --------------------------- 3.7/11.9 MB 279.5 kB/s eta 0:00:30\n",
      "   ------------ --------------------------- 3.7/11.9 MB 279.5 kB/s eta 0:00:30\n",
      "   ------------ --------------------------- 3.7/11.9 MB 279.5 kB/s eta 0:00:30\n",
      "   ------------ --------------------------- 3.7/11.9 MB 279.5 kB/s eta 0:00:30\n",
      "   ------------ --------------------------- 3.7/11.9 MB 279.5 kB/s eta 0:00:30\n",
      "   ------------ --------------------------- 3.7/11.9 MB 279.5 kB/s eta 0:00:30\n",
      "   ------------- -------------------------- 3.9/11.9 MB 267.5 kB/s eta 0:00:30\n",
      "   ------------- -------------------------- 3.9/11.9 MB 267.5 kB/s eta 0:00:30\n",
      "   ------------- -------------------------- 3.9/11.9 MB 267.5 kB/s eta 0:00:30\n",
      "   ------------- -------------------------- 3.9/11.9 MB 267.5 kB/s eta 0:00:30\n",
      "   -------------- ------------------------- 4.2/11.9 MB 269.7 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 4.2/11.9 MB 269.7 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 4.2/11.9 MB 269.7 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 4.5/11.9 MB 275.6 kB/s eta 0:00:28\n",
      "   -------------- ------------------------- 4.5/11.9 MB 275.6 kB/s eta 0:00:28\n",
      "   -------------- ------------------------- 4.5/11.9 MB 275.6 kB/s eta 0:00:28\n",
      "   -------------- ------------------------- 4.5/11.9 MB 275.6 kB/s eta 0:00:28\n",
      "   --------------- ------------------------ 4.7/11.9 MB 278.2 kB/s eta 0:00:26\n",
      "   --------------- ------------------------ 4.7/11.9 MB 278.2 kB/s eta 0:00:26\n",
      "   --------------- ------------------------ 4.7/11.9 MB 278.2 kB/s eta 0:00:26\n",
      "   --------------- ------------------------ 4.7/11.9 MB 278.2 kB/s eta 0:00:26\n",
      "   --------------- ------------------------ 4.7/11.9 MB 278.2 kB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 275.7 kB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 275.7 kB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 275.7 kB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 275.7 kB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 275.7 kB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 275.7 kB/s eta 0:00:26\n",
      "   ----------------- ---------------------- 5.2/11.9 MB 272.7 kB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 5.2/11.9 MB 272.7 kB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 5.2/11.9 MB 272.7 kB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 5.2/11.9 MB 272.7 kB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 5.2/11.9 MB 272.7 kB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 5.2/11.9 MB 272.7 kB/s eta 0:00:25\n",
      "   ------------------ --------------------- 5.5/11.9 MB 268.5 kB/s eta 0:00:24\n",
      "   ------------------ --------------------- 5.5/11.9 MB 268.5 kB/s eta 0:00:24\n",
      "   ------------------ --------------------- 5.5/11.9 MB 268.5 kB/s eta 0:00:24\n",
      "   ------------------ --------------------- 5.5/11.9 MB 268.5 kB/s eta 0:00:24\n",
      "   ------------------- -------------------- 5.8/11.9 MB 269.5 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 5.8/11.9 MB 269.5 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 5.8/11.9 MB 269.5 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 5.8/11.9 MB 269.5 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 5.8/11.9 MB 269.5 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 5.8/11.9 MB 269.5 kB/s eta 0:00:23\n",
      "   -------------------- ------------------- 6.0/11.9 MB 266.6 kB/s eta 0:00:23\n",
      "   -------------------- ------------------- 6.0/11.9 MB 266.6 kB/s eta 0:00:23\n",
      "   -------------------- ------------------- 6.0/11.9 MB 266.6 kB/s eta 0:00:23\n",
      "   -------------------- ------------------- 6.0/11.9 MB 266.6 kB/s eta 0:00:23\n",
      "   -------------------- ------------------- 6.0/11.9 MB 266.6 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 6.3/11.9 MB 264.8 kB/s eta 0:00:22\n",
      "   --------------------- ------------------ 6.3/11.9 MB 264.8 kB/s eta 0:00:22\n",
      "   --------------------- ------------------ 6.3/11.9 MB 264.8 kB/s eta 0:00:22\n",
      "   --------------------- ------------------ 6.3/11.9 MB 264.8 kB/s eta 0:00:22\n",
      "   --------------------- ------------------ 6.3/11.9 MB 264.8 kB/s eta 0:00:22\n",
      "   --------------------- ------------------ 6.3/11.9 MB 264.8 kB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 6.6/11.9 MB 263.2 kB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 6.6/11.9 MB 263.2 kB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 6.6/11.9 MB 263.2 kB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 6.6/11.9 MB 263.2 kB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 6.6/11.9 MB 263.2 kB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 261.8 kB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 7.1/11.9 MB 250.5 kB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 7.1/11.9 MB 250.5 kB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 7.1/11.9 MB 250.5 kB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 7.1/11.9 MB 250.5 kB/s eta 0:00:20\n",
      "   ------------------------ --------------- 7.3/11.9 MB 252.5 kB/s eta 0:00:19\n",
      "   ------------------------ --------------- 7.3/11.9 MB 252.5 kB/s eta 0:00:19\n",
      "   ------------------------ --------------- 7.3/11.9 MB 252.5 kB/s eta 0:00:19\n",
      "   ------------------------ --------------- 7.3/11.9 MB 252.5 kB/s eta 0:00:19\n",
      "   ------------------------ --------------- 7.3/11.9 MB 252.5 kB/s eta 0:00:19\n",
      "   ------------------------ --------------- 7.3/11.9 MB 252.5 kB/s eta 0:00:19\n",
      "   ------------------------ --------------- 7.3/11.9 MB 252.5 kB/s eta 0:00:19\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   ------------------------- -------------- 7.6/11.9 MB 249.4 kB/s eta 0:00:18\n",
      "   -------------------------- ------------- 7.9/11.9 MB 231.8 kB/s eta 0:00:18\n",
      "   -------------------------- ------------- 7.9/11.9 MB 231.8 kB/s eta 0:00:18\n",
      "   -------------------------- ------------- 7.9/11.9 MB 231.8 kB/s eta 0:00:18\n",
      "   --------------------------- ------------ 8.1/11.9 MB 236.1 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 8.1/11.9 MB 236.1 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 8.1/11.9 MB 236.1 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 8.1/11.9 MB 236.1 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 8.1/11.9 MB 236.1 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 8.1/11.9 MB 236.1 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 8.1/11.9 MB 236.1 kB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 231.1 kB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 231.1 kB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 231.1 kB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 231.1 kB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 231.1 kB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 8.7/11.9 MB 231.9 kB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 8.7/11.9 MB 231.9 kB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 8.7/11.9 MB 231.9 kB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 8.7/11.9 MB 231.9 kB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 8.7/11.9 MB 231.9 kB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 230.1 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 230.1 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 230.1 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 230.1 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 230.1 kB/s eta 0:00:14\n",
      "   ------------------------------ --------- 9.2/11.9 MB 230.5 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 9.2/11.9 MB 230.5 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 9.2/11.9 MB 230.5 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 9.2/11.9 MB 230.5 kB/s eta 0:00:12\n",
      "   ------------------------------- -------- 9.4/11.9 MB 229.5 kB/s eta 0:00:11\n",
      "   ------------------------------- -------- 9.4/11.9 MB 229.5 kB/s eta 0:00:11\n",
      "   ------------------------------- -------- 9.4/11.9 MB 229.5 kB/s eta 0:00:11\n",
      "   -------------------------------- ------- 9.7/11.9 MB 232.6 kB/s eta 0:00:10\n",
      "   -------------------------------- ------- 9.7/11.9 MB 232.6 kB/s eta 0:00:10\n",
      "   -------------------------------- ------- 9.7/11.9 MB 232.6 kB/s eta 0:00:10\n",
      "   -------------------------------- ------- 9.7/11.9 MB 232.6 kB/s eta 0:00:10\n",
      "   --------------------------------- ------ 10.0/11.9 MB 233.9 kB/s eta 0:00:09\n",
      "   --------------------------------- ------ 10.0/11.9 MB 233.9 kB/s eta 0:00:09\n",
      "   --------------------------------- ------ 10.0/11.9 MB 233.9 kB/s eta 0:00:09\n",
      "   --------------------------------- ------ 10.0/11.9 MB 233.9 kB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 10.2/11.9 MB 236.0 kB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 10.2/11.9 MB 236.0 kB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 10.2/11.9 MB 236.0 kB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 10.2/11.9 MB 236.0 kB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 10.5/11.9 MB 237.4 kB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 10.5/11.9 MB 237.4 kB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 10.5/11.9 MB 237.4 kB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 10.5/11.9 MB 237.4 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 10.7/11.9 MB 236.8 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 10.7/11.9 MB 236.8 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 10.7/11.9 MB 236.8 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 10.7/11.9 MB 236.8 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 11.0/11.9 MB 241.5 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 11.0/11.9 MB 241.5 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 11.0/11.9 MB 241.5 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 11.0/11.9 MB 241.5 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 11.0/11.9 MB 241.5 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 11.0/11.9 MB 241.5 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 11.3/11.9 MB 239.4 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 11.3/11.9 MB 239.4 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 11.3/11.9 MB 239.4 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 11.3/11.9 MB 239.4 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.5/11.9 MB 236.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  11.8/11.9 MB 228.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.9/11.9 MB 230.9 kB/s  0:00:47\n",
      "Downloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2026.2.16-py3-none-any.whl (233 kB)\n",
      "Building wheels for collected packages: lime\n",
      "  Building wheel for lime (pyproject.toml): started\n",
      "  Building wheel for lime (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283918 sha256=4ffe00bb9c0e40e578984098a30c74903f225ab02195eb0c1c4cf7ef89c95cef\n",
      "  Stored in directory: c:\\users\\lenova\\appdata\\local\\pip\\cache\\wheels\\7c\\04\\5c\\157dc9106512a6c7a30653ec064490c94a49e0fc8f63d19ab9\n",
      "Successfully built lime\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image, lime\n",
      "\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   -------- ------------------------------- 1/5 [lazy-loader]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [lime]\n",
      "   -------------------------------- ------- 4/5 [lime]\n",
      "   ---------------------------------------- 5/5 [lime]\n",
      "\n",
      "Successfully installed imageio-2.37.2 lazy-loader-0.4 lime-0.2.0.1 scikit-image-0.26.0 tifffile-2026.2.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lime scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dfff591",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:801\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    800\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    803\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     52\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\datasets\\folder.py:247\u001b[39m, in \u001b[36mDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    245\u001b[39m sample = \u001b[38;5;28mself\u001b[39m.loader(path)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    249\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:1820\u001b[39m, in \u001b[36mGaussianBlur.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m   1812\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1813\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   1814\u001b[39m \u001b[33;03m    img (PIL Image or Tensor): image to be blurred.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1817\u001b[39m \u001b[33;03m    PIL Image or Tensor: Gaussian blurred image\u001b[39;00m\n\u001b[32m   1818\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1819\u001b[39m sigma = \u001b[38;5;28mself\u001b[39m.get_params(\u001b[38;5;28mself\u001b[39m.sigma[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.sigma[\u001b[32m1\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1820\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1380\u001b[39m, in \u001b[36mgaussian_blur\u001b[39m\u001b[34m(img, kernel_size, sigma)\u001b[39m\n\u001b[32m   1376\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be PIL Image or Tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1378\u001b[39m     t_img = pil_to_tensor(img)\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m output = \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.Tensor):\n\u001b[32m   1383\u001b[39m     output = to_pil_image(output, mode=img.mode)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenova\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:761\u001b[39m, in \u001b[36mgaussian_blur\u001b[39m\u001b[34m(img, kernel_size, sigma)\u001b[39m\n\u001b[32m    759\u001b[39m padding = [kernel_size[\u001b[32m0\u001b[39m] // \u001b[32m2\u001b[39m, kernel_size[\u001b[32m0\u001b[39m] // \u001b[32m2\u001b[39m, kernel_size[\u001b[32m1\u001b[39m] // \u001b[32m2\u001b[39m, kernel_size[\u001b[32m1\u001b[39m] // \u001b[32m2\u001b[39m]\n\u001b[32m    760\u001b[39m img = torch_pad(img, padding, mode=\u001b[33m\"\u001b[39m\u001b[33mreflect\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m img = \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    763\u001b[39m img = _cast_squeeze_out(img, need_cast, need_squeeze, out_dtype)\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {running_loss:.4f}\")\n",
    "    print(f\"Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d6ac51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ v3 model saved successfully\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = r\"D:\\Users\\Lenova\\Desktop\\YukTha\\models\\mobilenet_food_model_v3.pth\"\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print(\"ğŸ”¥ v3 model saved successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc665731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/6]\n",
      "Train Loss: 22.1334\n",
      "Train Acc: 0.9597\n",
      "Val Acc: 0.9567\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "val_acc = val_correct / val_total\n",
    "\n",
    "print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
    "print(f\"Train Loss: {train_loss:.4f}\")\n",
    "print(f\"Train Acc: {train_acc:.4f}\")\n",
    "print(f\"Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved!\n",
      "\n",
      "Training Complete.\n",
      "Best Validation Accuracy: 0.9566666666666667\n"
     ]
    }
   ],
   "source": [
    "if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(),\n",
    "                   r\"D:\\Users\\Lenova\\Desktop\\YukTha\\models\\mobilenet_food_model_v3.pth\")\n",
    "        print(\"Best model saved!\")\n",
    "        trigger_times = 0\n",
    "else:\n",
    "        trigger_times += 1\n",
    "        print(f\"No improvement. Patience: {trigger_times}/{patience}\")\n",
    "\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "             \n",
    "\n",
    "print(\"\\nTraining Complete.\")\n",
    "print(\"Best Validation Accuracy:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11418603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 0, 'real': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1526a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[297   3]\n",
      " [ 23 277]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.93      0.99      0.96       300\n",
      "          AI       0.99      0.92      0.96       300\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Detailed Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Real\", \"AI\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d178280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 0, 'real': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c253a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = r\"D:\\Users\\Lenova\\Desktop\\YukTha\\models\\mobilenet_food_model_v3.pth\"\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print(\"ğŸ”¥ v3 model saved successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
